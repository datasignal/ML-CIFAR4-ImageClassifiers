{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import functions used in the different notebooks of the course project\n",
    "%run Tools.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Important :\n",
    "\n",
    "Because Github file size limitation, I was not able to commit the random forest model that is more 100 MB large. In consequence, it is not possible to execute this notebook. The test accuracy and predictions are collected from the saved models...\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will :\n",
    "\n",
    "1. For each of the previously built and saved models, we will compute their accuracy and predictions on the same test set used across all the notebooks. \n",
    "\n",
    "2. We will select the best and/or my favorite model and predict the labels on the final test set for which we don't know the true target values.\n",
    "\n",
    "3. Because I am curious, we will also build a basic meta model (most frequent predicted class) from the predictions of each models and look if we can improve predictions by using them together (or some of them). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load overfeat and pixels data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfeat shape: (5000, 4096)\n",
      "Pixels shape: (5000, 3072)\n",
      "Labels shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "# load the datasets\n",
    "overfeat, pixels, labels, names = load_data()\n",
    "\n",
    "# check shapes\n",
    "print('Overfeat shape:', overfeat.shape)\n",
    "print('Pixels shape:', pixels.shape)\n",
    "print('Labels shape:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the same test set than in the previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfeat test shape: (1000, 4096) (1000,)\n",
      "Pixels test shape: (1000, 3072) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# split the train/test sets (4000/1000 stratified split)\n",
    "X_overfeat_train, X_overfeat_test, y_train, y_test = split_data_stratified(overfeat, labels)\n",
    "X_pixels_train, X_pixels_test, _, _ = split_data_stratified(pixels, labels)\n",
    "\n",
    "print('Overfeat test shape:', X_overfeat_test.shape, y_test.shape)\n",
    "print('Pixels test shape:', X_pixels_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale data for the neuronal networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuronal networks need some data pre-processing : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale data for the fully-connected neuronal network\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_overfeat_train)\n",
    "X_overfeat_test_rescaled = scaler.transform(X_overfeat_test)\n",
    "\n",
    "# rescale data for the convolutional neuronal network\n",
    "X_pixels_test_rescaled = (X_pixels_test - 128) / 255\n",
    "X_pixels_test_rescaled = X_pixels_test_rescaled.reshape(-1, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test accuracy and predictions for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_best_models/fcnn/fcnn_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from saved_best_models/cnn/cnn_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# model filenames on disk\n",
    "filenames = {\n",
    "    'k-NN': 'saved_best_models/knn_model.npy',\n",
    "    'decision tree': 'saved_best_models/decision_tree_model.npy',\n",
    "    'random forest': 'saved_best_models/random_forest_model.npy',\n",
    "    'svm linear': 'saved_best_models/svm_linear_model.npy',\n",
    "    'svm rbf': 'saved_best_models/svm_rbf_model.npy',\n",
    "    'logistic': 'saved_best_models/logistic_regression_model.npy',\n",
    "    'fc nn': 'saved_best_models/fcnn/fcnn_model.ckpt',\n",
    "    'cnn': 'saved_best_models/cnn/cnn_model.ckpt'\n",
    "}\n",
    "\n",
    "test_accuracies = {}\n",
    "features = []\n",
    "predictions = []\n",
    "for key, filename in filenames.items():\n",
    "    \n",
    "    features.append(key)\n",
    "    \n",
    "    # accuracy evaluation on test data\n",
    "    if key == 'fc nn':\n",
    "        # delete the current graph\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        # import the graph from the file\n",
    "        graph = tf.train.import_meta_graph(filename + '.meta')\n",
    "\n",
    "        # Load the network from file\n",
    "        with tf.Session() as sess:\n",
    "        \n",
    "            # load trained variables\n",
    "            graph.restore(sess, filename)\n",
    "    \n",
    "            # evaluate test accuracy\n",
    "            test_accuracy = sess.run('Accuracy:0', feed_dict={\n",
    "                'X:0': X_overfeat_test_rescaled,\n",
    "                'Y:0': y_test,\n",
    "                'Training:0': False\n",
    "            })\n",
    "            \n",
    "            # get predictions\n",
    "            model_predictions = sess.run('Predictions:0', feed_dict={\n",
    "                'X:0': X_overfeat_test_rescaled,\n",
    "                'Training:0': False\n",
    "            })\n",
    "            \n",
    "    elif key == 'cnn':\n",
    "        # delete the current graph\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        # import the graph from the file\n",
    "        graph = tf.train.import_meta_graph(filename + '.meta')\n",
    "\n",
    "        # Load the network from file\n",
    "        with tf.Session() as sess:\n",
    "        \n",
    "            # load trained variables\n",
    "            graph.restore(sess, filename)\n",
    "    \n",
    "            # evaluate test accuracy\n",
    "            test_accuracy = sess.run('Accuracy:0', feed_dict={\n",
    "                'X:0': X_pixels_test_rescaled,\n",
    "                'Y:0': y_test,\n",
    "                'Training:0': False\n",
    "            })\n",
    "            \n",
    "            # get predictions\n",
    "            model_predictions = sess.run('Predictions:0', feed_dict={\n",
    "                'X:0': X_pixels_test_rescaled,\n",
    "                'Training:0': False\n",
    "            })\n",
    "    else:\n",
    "        # load model\n",
    "        model = np.load(filename, allow_pickle=True).item(0)\n",
    "        model_predictions = model.predict(X_overfeat_test)\n",
    "        test_accuracy = model.score(X_overfeat_test, y_test)\n",
    "    \n",
    "    # store test accuracy\n",
    "    test_accuracies[key] = test_accuracy\n",
    "    \n",
    "    # store model predictions\n",
    "    predictions.append(model_predictions.reshape(-1, 1))\n",
    "\n",
    "# Build a dataframe with the predictions from each model\n",
    "predictions = np.concatenate(predictions, axis=1)\n",
    "df_predictions = pd.DataFrame(predictions, columns=features)\n",
    "\n",
    "# Collect test accuracies in a dataframe\n",
    "df_test_accuracy = pd.DataFrame.from_dict({'test accuracy': test_accuracies}).sort_values(by='test accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm rbf</th>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc nn</th>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm linear</th>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-NN</th>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               test accuracy\n",
       "svm rbf                0.842\n",
       "fc nn                  0.838\n",
       "cnn                    0.834\n",
       "svm linear             0.830\n",
       "logistic               0.828\n",
       "random forest          0.781\n",
       "k-NN                   0.780\n",
       "decision tree          0.666"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show test accuracy of each model\n",
    "df_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is of course exactly the same test accuracy presented in the different notebooks but it's great to have the models usable as a piece of software if we want. Which one to choose ?\n",
    "\n",
    "First, our image classifier use case clearly don't force us to choose a model that is good to explain why and how things works. Decision tree are good to understand the logic behind the results but here it is not required and the results a far behind. k-NN and random forest return good results but there is no real good reason to select them as our best model if best prediction accuracy is the goal. \n",
    "\n",
    "Note that if the use case of the model would be to find similar images, k-NN would be a good and intuitive model to work with and my choice because accuracy would not be the most important factor. Proposing enough similar images to a user would suffice to create a good app functionality.\n",
    "\n",
    "So, it remains the 80%+ models, with similar accuracy and discutable ovefitting for some of them, even if cross-validation was done as a safety belt and help us to tune the different hyperparameters. Note that the convolutional neuronal network is very different from the other models because it is the only one that use the pixels data as its data source and it is a great feature. We can find images on google, rescale them to 32x32 pixels and use our model with hope to have good predictions. All other models can't do that because they are based on the OverFeat convolutional neural network. At least, some development will be required to link the trained OverFeat CNN model with our own models to get some new images predictions.\n",
    "\n",
    "From the overfeat data, it is the svm rbf model that gived us the best results with a test accuracy identical to the validation accuracy predicted by cross-validation. It was a time consuming model to tune and there is more than 9% difference between the training and validation accuracy. Our two SVM models are strong and would be good choices.\n",
    "\n",
    "One of my favorite model is the logistic regression model because we obtained a good test accuracy, identical to the validation accuracy predicted by cross-validation but with less overfitting, less than 3% difference with the training accuracy. Moreover, logistic regression models are probabilistic classifiers and it allows to know for each images the probabilities to belong to each class. It's a nice feature because it can be used to tune/understand the model and it offers nice app functionality opportunities. Depending the use case, the client who needs it, I would choose this model because its possible to explain, prove and try to solve misclassifications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute predictions on the final cifar_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cifar_test data\n",
    "with np.load('cifar4-test.npz', allow_pickle=False) as npz:            \n",
    "    overfeat_final = npz['overfeat'].astype(np.float32)\n",
    "    pixels_final   = npz['pixels'].astype(np.float32)\n",
    "    \n",
    "    # rescale pixels data for the CNN model\n",
    "    pixels_final_rescaled = (pixels_final - 128) / 255\n",
    "    pixels_final_rescaled = pixels_final_rescaled.reshape(-1, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_best_models/cnn/cnn_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Get CNN predictions\n",
    "tf.reset_default_graph()\n",
    "graph = tf.train.import_meta_graph('saved_best_models/cnn/cnn_model.ckpt.meta')\n",
    "with tf.Session() as sess:\n",
    "    graph.restore(sess, filename)        \n",
    "    final_predictions = sess.run('Predictions:0', feed_dict={\n",
    "        'X:0': pixels_final_rescaled,\n",
    "        'Training:0': False\n",
    "    })\n",
    "    \n",
    "# Save CNN predictions\n",
    "np.save('test-predictions.npy', final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logistic regression predictions\n",
    "model = np.load(filenames['logistic'], allow_pickle=True).item(0)\n",
    "final_predictions = model.predict(overfeat_final)\n",
    "\n",
    "# Save logistic regression predictions\n",
    "np.save('test-predictions-logistic.npy', final_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional - Most-frequent predicted class meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k-NN</th>\n",
       "      <th>decision tree</th>\n",
       "      <th>random forest</th>\n",
       "      <th>svm linear</th>\n",
       "      <th>svm rbf</th>\n",
       "      <th>logistic</th>\n",
       "      <th>fc nn</th>\n",
       "      <th>cnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k-NN  decision tree  random forest  svm linear  svm rbf  logistic  fc nn  \\\n",
       "0     2              2              2           2        3         3      2   \n",
       "1     2              3              3           2        2         2      2   \n",
       "2     2              3              2           2        1         2      2   \n",
       "3     0              0              0           0        0         0      0   \n",
       "4     2              2              2           2        2         2      3   \n",
       "5     0              0              0           0        0         0      0   \n",
       "6     2              1              2           2        2         2      2   \n",
       "7     0              0              0           0        0         0      0   \n",
       "8     0              1              2           0        0         0      0   \n",
       "9     1              0              1           1        1         1      1   \n",
       "\n",
       "   cnn  \n",
       "0    2  \n",
       "1    3  \n",
       "2    1  \n",
       "3    0  \n",
       "4    2  \n",
       "5    1  \n",
       "6    2  \n",
       "7    0  \n",
       "8    2  \n",
       "9    1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show some predictions\n",
    "df_predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting to see that it seems not rare to have 3 differents predicted classes if we ask all the models.\n",
    "We will drop the decision tree model from our meta model because its accuracy is far behind and trees are already represented by the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most frequent predicted class for each image\n",
    "most_frequent_predictions = np.zeros_like(y_test)\n",
    "for i in range(y_test.shape[0]):\n",
    "    most_frequent_predictions[i] = np.argmax(np.bincount(df_predictions.drop(['decision tree'], axis=1).values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most-frequent predicted class model accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy\n",
    "accuracy = (most_frequent_predictions == y_test).sum() / y_test.shape[0]\n",
    "print('Most-frequent predicted class model accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using predictions done by different models looks an interesting way to improve accuracy. This approach is rough and naive but it is clear that there are opportunities to improve accuracy with multiple models... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
